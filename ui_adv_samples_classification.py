# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'ui_adv_samples_classification.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
import pyttsx3
from PyQt5.Qt import QApplication, QWidget, QPushButton,QThread,QMutex,QButtonGroup
from PyQt5.QtGui import QIcon
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.Qt import pyqtSignal
from PyQt5.QtCore import QUrl
import matplotlib.pyplot as plt
from PyQt5.QtWidgets import QFileDialog
import numpy as np
import data
import model
import time
from PIL import Image
import seaborn as sns
sns.set_theme(style="whitegrid")
sns.set_style('darkgrid')
import joblib
import torch
import torch.nn.functional as F
import torch.nn as nn
from torchvision.transforms.functional import normalize, resize, to_pil_image
from torchvision.io import read_image
from torchcam.cams import cam
from torchcam.utils import overlay_mask
import torch.optim as optim
from torch.autograd import Variable
import torchvision
from torchvision import datasets, models, transforms
from torch.utils.data import TensorDataset,DataLoader
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import scipy.misc as im
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
plt.switch_backend('TKAgg')
from torchvision import transforms
from tqdm import trange,tqdm
from torch.optim import lr_scheduler
from art.attacks.evasion import ProjectedGradientDescent,DeepFool,CarliniLInfMethod,ThresholdAttack
from art.estimators.classification import PyTorchClassifier
from openpyxl import load_workbook
from torchvision.utils import save_image
import matplotlib as mpl
device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
mpl.rcParams["font.sans-serif"] = ["SimHei"]
mpl.rcParams["axes.unicode_minus"] = False


class Ui_CNN_data_test(object):
    def setupUi(self, CNN_dataset_test):
        CNN_dataset_test.setObjectName("CNN_dataset_test")
        CNN_dataset_test.resize(1757, 781)
        CNN_dataset_test.setStyleSheet("background-color: rgb(246, 250, 255);")
        font = QtGui.QFont()
        font.setPointSize(10)
        CNN_dataset_test.setFont(font)
        self.label_2 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_2.setGeometry(QtCore.QRect(36, 30, 221, 41))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label_2.setFont(font)
        self.label_2.setObjectName("label_2")
        self.pushButton = QtWidgets.QPushButton(CNN_dataset_test)
        self.pushButton.setGeometry(QtCore.QRect(270, 392, 181, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(14)
        self.pushButton.setFont(font)
        self.pushButton.setObjectName("pushButton")
        self.label_21 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_21.setGeometry(QtCore.QRect(35, 123, 211, 41))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label_21.setFont(font)
        self.label_21.setObjectName("label_21")
        self.label_image_show = QtWidgets.QLabel(CNN_dataset_test)
        self.label_image_show.setGeometry(QtCore.QRect(60, 451, 291, 271))
        self.label_image_show.setStyleSheet("background-color: rgb(255, 255, 255);")
        self.label_image_show.setText("")
        self.label_image_show.setObjectName("label_image_show")
        self.label = QtWidgets.QLabel(CNN_dataset_test)
        self.label.setGeometry(QtCore.QRect(90, 727, 234, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label.setFont(font)
        self.label.setAlignment(QtCore.Qt.AlignCenter)
        self.label.setObjectName("label")
        self.lineEdit_CNN_classification_imagetest_model_address = QtWidgets.QLineEdit(CNN_dataset_test)
        self.lineEdit_CNN_classification_imagetest_model_address.setGeometry(QtCore.QRect(93, 80, 531, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(11)
        self.lineEdit_CNN_classification_imagetest_model_address.setFont(font)
        self.lineEdit_CNN_classification_imagetest_model_address.setStyleSheet("background-color: rgb(243, 243, 243);")
        self.lineEdit_CNN_classification_imagetest_model_address.setAlignment(QtCore.Qt.AlignCenter)
        self.lineEdit_CNN_classification_imagetest_model_address.setObjectName("lineEdit_CNN_classification_imagetest_model_address")
        self.pushButton_CNN_classification_imagetest_model_address = QtWidgets.QPushButton(CNN_dataset_test)
        self.pushButton_CNN_classification_imagetest_model_address.setGeometry(QtCore.QRect(623, 80, 31, 31))
        self.pushButton_CNN_classification_imagetest_model_address.setStyleSheet("background-color: rgb(98, 98, 98);")
        self.pushButton_CNN_classification_imagetest_model_address.setObjectName("pushButton_CNN_classification_imagetest_model_address")
        self.label_4 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_4.setGeometry(QtCore.QRect(37, 235, 231, 41))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label_4.setFont(font)
        self.label_4.setObjectName("label_4")
        self.label_image_show_2 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_image_show_2.setGeometry(QtCore.QRect(380, 451, 281, 271))
        self.label_image_show_2.setStyleSheet("background-color: rgb(255, 255, 255);")
        self.label_image_show_2.setText("")
        self.label_image_show_2.setObjectName("label_image_show_2")
        self.label_3 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_3.setGeometry(QtCore.QRect(380, 727, 289, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label_3.setFont(font)
        self.label_3.setAlignment(QtCore.Qt.AlignCenter)
        self.label_3.setObjectName("label_3")
        self.radioButton_2 = QtWidgets.QRadioButton(CNN_dataset_test)
        self.radioButton_2.setGeometry(QtCore.QRect(271, 188, 121, 21))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_2.setFont(font)
        self.radioButton_2.setObjectName("radioButton_2")
        self.radioButton_4 = QtWidgets.QRadioButton(CNN_dataset_test)
        self.radioButton_4.setGeometry(QtCore.QRect(60, 187, 89, 21))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_4.setFont(font)
        self.radioButton_4.setChecked(True)
        self.radioButton_4.setObjectName("radioButton_4")
        self.radioButton = QtWidgets.QRadioButton(CNN_dataset_test)
        self.radioButton.setGeometry(QtCore.QRect(397, 188, 151, 21))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton.setFont(font)
        self.radioButton.setObjectName("radioButton")
        self.radioButton_3 = QtWidgets.QRadioButton(CNN_dataset_test)
        self.radioButton_3.setGeometry(QtCore.QRect(148, 187, 101, 21))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_3.setFont(font)
        self.radioButton_3.setObjectName("radioButton_3")
        self.radioButton_11 = QtWidgets.QRadioButton(CNN_dataset_test)
        self.radioButton_11.setGeometry(QtCore.QRect(553, 185, 131, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_11.setFont(font)
        self.radioButton_11.setObjectName("radioButton_11")
        self.frame = QtWidgets.QFrame(CNN_dataset_test)
        self.frame.setGeometry(QtCore.QRect(33, 297, 651, 91))
        self.frame.setFrameShape(QtWidgets.QFrame.StyledPanel)
        self.frame.setFrameShadow(QtWidgets.QFrame.Raised)
        self.frame.setObjectName("frame")
        self.radioButton_8 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_8.setGeometry(QtCore.QRect(115, 3, 121, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_8.setFont(font)
        self.radioButton_8.setObjectName("radioButton_8")
        self.radioButton_5 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_5.setGeometry(QtCore.QRect(26, 9, 89, 20))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_5.setFont(font)
        self.radioButton_5.setObjectName("radioButton_5")
        self.radioButton_6 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_6.setGeometry(QtCore.QRect(238, 10, 89, 16))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_6.setFont(font)
        self.radioButton_6.setChecked(True)
        self.radioButton_6.setObjectName("radioButton_6")
        self.radioButton_7 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_7.setGeometry(QtCore.QRect(351, 8, 139, 20))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_7.setFont(font)
        self.radioButton_7.setObjectName("radioButton_7")
        self.radioButton_10 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_10.setGeometry(QtCore.QRect(516, 9, 89, 16))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.radioButton_10.setFont(font)
        self.radioButton_10.setChecked(False)
        self.radioButton_10.setObjectName("radioButton_10")
        self.label_5 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_5.setGeometry(QtCore.QRect(772, 497, 371, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label_5.setFont(font)
        self.label_5.setAlignment(QtCore.Qt.AlignCenter)
        self.label_5.setObjectName("label_5")
        self.label_image_show_4 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_image_show_4.setGeometry(QtCore.QRect(1237, 11, 511, 481))
        self.label_image_show_4.setStyleSheet("background-color: rgb(255, 255, 255);")
        self.label_image_show_4.setText("")
        self.label_image_show_4.setObjectName("label_image_show_4")
        self.label_image_show_3 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_image_show_3.setGeometry(QtCore.QRect(715, 10, 511, 481))
        self.label_image_show_3.setStyleSheet("background-color: rgb(255, 255, 255);")
        self.label_image_show_3.setText("")
        self.label_image_show_3.setAlignment(QtCore.Qt.AlignHCenter|QtCore.Qt.AlignTop)
        self.label_image_show_3.setObjectName("label_image_show_3")
        self.label_6 = QtWidgets.QLabel(CNN_dataset_test)
        self.label_6.setGeometry(QtCore.QRect(1270, 496, 451, 31))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(13)
        self.label_6.setFont(font)
        self.label_6.setAlignment(QtCore.Qt.AlignCenter)
        self.label_6.setObjectName("label_6")
        self.Result_show = QtWidgets.QLabel(CNN_dataset_test)
        self.Result_show.setGeometry(QtCore.QRect(730, 560, 1021, 191))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(11)
        self.Result_show.setFont(font)
        self.Result_show.setLayoutDirection(QtCore.Qt.LeftToRight)
        self.Result_show.setAlignment(QtCore.Qt.AlignLeading|QtCore.Qt.AlignLeft|QtCore.Qt.AlignTop)
        self.Result_show.setObjectName("Result_show")

        btngroup1 = QButtonGroup(CNN_dataset_test)
        btngroup1.addButton(self.radioButton)
        btngroup1.addButton(self.radioButton_2)
        btngroup1.addButton(self.radioButton_3)
        btngroup1.addButton(self.radioButton_4)
        btngroup1.addButton(self.radioButton_11)

        btngroup2 = QButtonGroup(CNN_dataset_test)
        btngroup2.addButton(self.radioButton_5)
        btngroup2.addButton(self.radioButton_6)
        btngroup2.addButton(self.radioButton_7)
        btngroup2.addButton(self.radioButton_8)
        btngroup2.addButton(self.radioButton_10)

        self.clean_img = "Data\Scene\\UCMerced_LandUse\\val\\buildings\\buildings98.tif"
        self.adv_img = r"D:\Data\Adv_Fool_Img\Adversarial Scene Dataset\UC_adv_fool\PGD\buildings\PGD_adv_generated_498.jpg"
        self.retranslateUi(CNN_dataset_test)
        QtCore.QMetaObject.connectSlotsByName(CNN_dataset_test)

    def retranslateUi(self, CNN_dataset_test):
        _translate = QtCore.QCoreApplication.translate
        CNN_dataset_test.setWindowTitle(_translate("CNN_dataset_test", "Recognition Test of Single Remote Sensing Image"))
        CNN_dataset_test.setWindowIcon(QIcon("./1.ico"))
        self.label_2.setText(_translate("CNN_dataset_test", "Model Address:"))
        self.pushButton.setText(_translate("CNN_dataset_test", "Start"))
        self.label_21.setText(_translate("CNN_dataset_test", "Select the Dataset:"))
        self.label.setText(_translate("CNN_dataset_test", "Current Benign Test Image"))
        self.lineEdit_CNN_classification_imagetest_model_address.setText(_translate("CNN_dataset_test", "pkl_save\\mstar_resnet18.pkl"))
        self.pushButton_CNN_classification_imagetest_model_address.setText(_translate("CNN_dataset_test", "…"))
        self.label_4.setText(_translate("CNN_dataset_test", "Select Attack Method："))
        self.label_3.setText(_translate("CNN_dataset_test", "Current Adversarial Test Image"))
        self.radioButton_2.setText(_translate("CNN_dataset_test", " AID"))
        self.radioButton_4.setText(_translate("CNN_dataset_test", "  UC"))
        self.radioButton.setText(_translate("CNN_dataset_test", " FUSAR-Ship"))
        self.radioButton_3.setText(_translate("CNN_dataset_test", " MSTAR"))
        self.radioButton_11.setText(_translate("CNN_dataset_test", " Sorted-Cars"))
        self.radioButton_8.setText(_translate("CNN_dataset_test", " Deepfool"))
        self.radioButton_5.setText(_translate("CNN_dataset_test", " PGD"))
        self.radioButton_6.setText(_translate("CNN_dataset_test", "  C&W"))
        self.radioButton_7.setText(_translate("CNN_dataset_test", " HopSkipJump"))
        self.radioButton_10.setText(_translate("CNN_dataset_test", " UAP"))
        self.label_5.setText(_translate("CNN_dataset_test", "Feature Activation Map for Benign Image"))
        self.label_6.setText(_translate("CNN_dataset_test", "Feature Activation Map for Adversarial Image"))
        self.Result_show.setText(_translate("CNN_dataset_test", "Results："))
        self.radioButton_4.setChecked(True)
        self.radioButton_5.setChecked(True)
        self.openimage_ori(self.clean_img)
        self.openimage_adv(self.adv_img)

    def caolianjie(self):
        # self.pushButton_CNN_classification_imagetest_image_address.clicked.connect(self.choose_CNN_dataset_test_data_dir)
        self.radioButton.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_2.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_3.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_4.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_5.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_6.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_7.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_8.toggled.connect(self.dataset_attack_select_set_visible)
        self.radioButton_10.toggled.connect(self.dataset_attack_select_set_visible)
        self.pushButton_CNN_classification_imagetest_model_address.clicked.connect(self.choose_CNN_dataset_test_model_dir)
        # self.pushButton.clicked.connect(self.clear_all)
        self.pushButton.clicked.connect(self.out_setting)
        # self.pushButton.clicked.connect(lambda :self.openimage_example(self.lineEdit_CNN_classification_imagetest_image_address.text()))
        self.pushButton.clicked.connect(
            lambda: self.CNN_dataset_test(self.clean_img, self.adv_img, self.dataset_name,
                                          self.lineEdit_CNN_classification_imagetest_model_address.text()))

    def out_setting(self):
        if self.radioButton.isChecked():
            self.dataset_name = 'fusarship'
        elif self.radioButton_2.isChecked():
            self.dataset_name = 'fgsc23'
        elif self.radioButton_3.isChecked():
            self.dataset_name = 'mstar'
        elif self.radioButton_4.isChecked():
            self.dataset_name = 'uc'
        elif self.radioButton_11.isChecked():
            self.dataset_name = 'sortedcars'
        if self.radioButton_5.isChecked():
            self.attack_name = "PGD"
        elif self.radioButton_6.isChecked():
            self.attack_name = "CW"
        elif self.radioButton_7.isChecked():
            self.attack_name = "HopSkipJump"
        elif self.radioButton_8.isChecked():
            self.attack_name = "Deepfool"
        elif self.radioButton_10.isChecked():
            self.attack_name = "UAP"


    def dataset_attack_select_set_visible(self):
        if self.radioButton_5.isChecked():
            if self.radioButton.isChecked():
                self.clean_img = "Data/目标/FUSAR_Ship_jpg/val/BulkCarrier/Ship_C01S02N0069.tiff-2022-11-07-10-56-42-795.jpg"
                self.adv_img = "Data/目标/FUSAR_Ship/对抗欺骗样本/PGD/BulkCarrier/PGD_adv_generated_6.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_2.isChecked():
                # data_dir = "Data\目标\\FGSC-23\\val_PGD.npy"
                self.clean_img = "Data\目标\FGSC-23\\val\航空母舰\\1_3_131_11231.jpg"
                self.adv_img = "Data\目标\FGSC-23\对抗欺骗样本\PGD\航空母舰\\PGD_adv_generated_134.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_3.isChecked():
                # data_dir = "Data\目标\\MSTAR-10\\val_PGD.npy"
                self.clean_img = "Data\目标\MSTAR-10\\val\ZIL131\\HB14931.025.jpeg"
                self.adv_img = "Data\目标\MSTAR-10\Mstar_对抗欺骗样本\PGD_L2_0.5\ZIL131\\ZIL1311.tif"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_4.isChecked():
                # data_dir = "Data\场景\\UCMerced_LandUse\\val_PGD.npy"
                self.clean_img = "Data\场景\\UCMerced_LandUse\\val\\buildings\\buildings98.tif"
                self.adv_img = r"D:\Data\Adv_Fool_Img\对抗欺骗场景数据集\光学场景_UC_adv_fool\PGD\buildings\PGD_adv_generated_498.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_11.isChecked():
                data_dir = "Data\目标\\Sorted_Cars\\val_PGD.npy"
            # self.lineEdit_CNN_classification_imagetest_image_address.setText()
            # print(self.lineEdit_CNN_classification_imagetest_image_address.text())

        elif self.radioButton_6.isChecked():
            if self.radioButton.isChecked():
                # data_dir = "Data\目标\\FUSAR_Ship\\val_CW.npy"
                self.clean_img = "Data/目标/FUSAR_Ship_jpg/val/BulkCarrier/Ship_C01S02N0042.tiff-2022-11-07-10-56-42-607.jpg"
                self.adv_img = "Data/目标/FUSAR_Ship/对抗欺骗样本/CW_Linf/BulkCarrier/CW_adv_generated_2.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_2.isChecked():
                self.clean_img = "Data\目标\FGSC-23\\val\航空母舰\\1_3_131_11231.jpg"
                self.adv_img = "Data/目标/FGSC-23/对抗欺骗样本/CW/航空母舰/CW_adv_generated_134.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_3.isChecked():
                self.clean_img = "Data\目标\MSTAR-10\\val\ZIL131\\HB14931.025.jpeg"
                self.adv_img = "Data\目标\MSTAR-10\Mstar_对抗欺骗样本\CW8\ZIL131\\ZIL1311.tif"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_4.isChecked():
                self.clean_img = "Data\场景\\UCMerced_LandUse\\val\\freeway\\freeway13.tif"
                self.adv_img = r"D:\Data\Adv_Fool_Img\对抗欺骗场景数据集\光学场景_UC_adv_fool\CW\freeway\\CW_adv_generated_813.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_11.isChecked():
                data_dir = "Data\目标\\Sorted_Cars\\val_CW.npy"

        elif self.radioButton_7.isChecked():
            if self.radioButton.isChecked():
                self.clean_img = "Data/目标/FUSAR_Ship_jpg/val/CargoShip/Ship_C01S07N0545.tiff-2022-11-07-10-59-25-870.jpg"
                self.adv_img = "Data/目标/FUSAR_Ship/对抗欺骗样本/HopSkipJump/CargoShip/HSJ_adv_generated_31.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_2.isChecked():
                self.clean_img = "Data\目标\FGSC-23\\val\航空母舰\\1_3_131_11231.jpg"
                self.adv_img = "Data\目标\FGSC-23\对抗欺骗样本\HopSkipJump\航空母舰\\HSJ_adv_generated_134.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_3.isChecked():
                self.clean_img = r"C:\Users\sunha\Desktop\pADV\Data\目标\MSTAR-10\All\BTR70(SN_C71)\HB03365.004.jpeg"
                self.adv_img = r'D:\Data\Adv_Fool_Img\对抗欺骗目标数据集\SAR车辆-MSTAR_adv_fool\HopSkipJump\BTR70(SN_C71)\BTR70(SN_C71)23.tif'
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_4.isChecked():
                self.clean_img = r"C:\Users\sunha\Desktop\pADV\Data\场景\UCMerced_LandUse\All\baseballdiamond\baseballdiamond03.tif"
                self.adv_img = r"D:\Data\Adv_Fool_Img\对抗欺骗场景数据集\光学场景_UC_adv_fool\HopSkipJump\baseballdiamond\HSJ_adv_generated_203.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_11.isChecked():
                data_dir = "Data\目标\\Sorted_Cars\\val_HopSkipJump.npy"

        elif self.radioButton_8.isChecked():
            if self.radioButton.isChecked():
                self.clean_img = "Data/目标/FUSAR_Ship_jpg/val/CargoShip/Ship_C01S07N0545.tiff-2022-11-07-10-59-25-870.jpg"
                self.adv_img = "Data/目标/FUSAR_Ship/对抗欺骗样本/DeepFool/CargoShip/DF_adv_generated_31.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_2.isChecked():
                self.clean_img = "Data\目标\FGSC-23\\val\航空母舰\\1_3_131_11231.jpg"
                self.adv_img = "Data\目标\FGSC-23\对抗欺骗样本\Deepfool\航空母舰\\DF_adv_generated_134.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_3.isChecked():
                self.clean_img = r"C:\Users\sunha\Desktop\pADV\Data\目标\MSTAR-10\val\2S1\HB14939.000.jpeg"
                self.adv_img = r"D:\Data\Adv_Fool_Img\对抗欺骗目标数据集\SAR车辆-MSTAR_adv_fool\Deepfool\2S1\2S19.tif"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_4.isChecked():
                self.clean_img = r'C:\Users\sunha\Desktop\pADV\Data\场景\UCMerced_LandUse\All\intersection\intersection98.tif'
                self.adv_img = r"D:\Data\Adv_Fool_Img\对抗欺骗场景数据集\光学场景_UC_adv_fool\Deepfool\intersection\Deepfool_adv_generated_1198.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_11.isChecked():
                data_dir = "Data\目标\\Sorted_Cars\\val_Deepfool.npy"


        elif self.radioButton_10.isChecked():
            if self.radioButton.isChecked():
                self.clean_img = "Data/目标/FUSAR_Ship_jpg/val/CargoShip/Ship_C01S07N0545.tiff-2022-11-07-10-59-25-870.jpg"
                self.adv_img = "Data/目标/FUSAR_Ship/对抗欺骗样本/DeepFool/CargoShip/DF_adv_generated_31.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_2.isChecked():
                self.clean_img = "Data\目标\FGSC-23\\val\航空母舰\\1_3_131_11231.jpg"
                self.adv_img = "Data\目标\FGSC-23\对抗欺骗样本\Deepfool\航空母舰\\DF_adv_generated_134.jpg"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_3.isChecked():
                self.clean_img = "Data\目标\MSTAR-10\\val\ZIL131\\HB14931.025.jpeg"
                self.adv_img = "Data\目标\MSTAR-10\Mstar_对抗欺骗样本\Deepfool\ZIL131\\ZIL1311.tif"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_4.isChecked():
                self.clean_img = "Data\场景\\UCMerced_LandUse\\val\\buildings\\buildings11.tif"
                self.adv_img = "D:\Data\Adv_Fool_Img\对抗欺骗场景数据集\光学场景_UC_adv_fool\\UAP\\buildings\\buildings11_adv.png"
                self.openimage_ori(self.clean_img)
                self.openimage_adv(self.adv_img)
            elif self.radioButton_11.isChecked():
                data_dir = "Data\目标\\Sorted_Cars\\val_Deepfool.npy"


    def CNN_dataset_test(self, clean_img_address, adv_img_address, dataset_name, model_address):
        print("eee")
        self.thread_image_test = Thread_CNN_adv_dataset_test(clean_img_address, adv_img_address, dataset_name, model_address)
        self.thread_image_test.update_datasettest.connect(self.get_CNN_dataset_test_result)
        self.thread_image_test.start()
        self.thread_image_test.exec()

    def get_CNN_dataset_test_result(self, test_result):
        self.Result_show.setText(test_result[0])
        self.Result_show.repaint()

        feature_result_clean = test_result[4]
        feature_result_adv = test_result[5]
        plt.imshow(feature_result_clean)
        plt.savefig('result_image/CNN_feature_visualize_1.jpg')
        self.openimage_featue(self.label_image_show_3,'result_image/CNN_feature_visualize_1.jpg')
        plt.imshow(feature_result_adv)
        plt.savefig('result_image/CNN_feature_visualize_2.jpg')
        self.openimage_featue(self.label_image_show_4,'result_image/CNN_feature_visualize_2.jpg')

        # fig_result_1 = sns.barplot(x=class_names,y=percentage_clean.tolist())
        # fig_result_1.set_title("原始样本分类置信度")
        # barplot_1 = fig_result_1.get_figure()
        # fig_path_1 = "result_image/barplot_1.png"
        # barplot_1.savefig(fig_path_1)
        # self.openimage_result(self.label_image_show_6,fig_path_1)
        #
        # fig_result_2 = sns.barplot(x=class_names,y=percentage_adv.tolist())
        # fig_result_2.set_title("对抗样本分类置信度")
        # barplot_2 = fig_result_2.get_figure()
        # fig_path_2 = "result_image/barplot_1.png"
        # barplot_2.savefig(fig_path_2)
        # self.openimage_result(self.label_image_show_5,fig_path_2)

        plt.close('all')

    def choose_CNN_dataset_test_model_dir(self):
        model_dir = QFileDialog.getOpenFileName(None, 'Choose data File', '')
        self.lineEdit_CNN_classification_imagetest_model_address.setText(model_dir[0])

    def openimage_featue(self, label_image_show,imgName):
        # imgName = imgName.replace('\\', '/')
        jpg = QtGui.QPixmap(imgName).scaled(label_image_show.width(), label_image_show.height())
        label_image_show.setPixmap(jpg)

    # def openimage_result(self, label_image_show,imgName):
    #     # imgName = imgName.replace('\\', '/')
    #     jpg = QtGui.QPixmap(imgName).scaled(320, 320)
    #     label_image_show.setPixmap(jpg)

    def openimage_ori(self,imgName):
        imgName = imgName.replace('\\', '/')
        jpg = QtGui.QPixmap(imgName).scaled(self.label_image_show.width(), self.label_image_show.height())
        # jpg = QtGui.QPixmap(imgName)
        self.label_image_show.setPixmap(jpg)

    def openimage_adv(self,imgName):
        imgName = imgName.replace('\\', '/')
        jpg = QtGui.QPixmap(imgName).scaled(self.label_image_show_2.width(), self.label_image_show_2.height())
        self.label_image_show_2.setPixmap(jpg)

class Ensemble(nn.Module):
    def __init__(self, models):
        super(Ensemble, self).__init__()
        self.models = models
        assert len(self.models) > 0

    def forward(self, x):
        if len(self.models) > 1:
            outputs = 0
            for model in self.models:
                outputs += F.softmax(model(x), dim=-1)
            output = outputs / len(self.models)
            output = torch.clamp(output, min=1e-40)
            return torch.log(output)
        else:
            return self.models[0](x)

class Thread_CNN_adv_dataset_test(QThread):
    update_datasettest = pyqtSignal(dict)

    def __init__(self, clean_img_address, adv_img_address, dataset_name, model_address):
        super().__init__()
        self.out = ['Results：', '\n', 'Address of Benign Image：',clean_img_address ,'\n',
                    'Address of Adversarial Image：',adv_img_address ,'\n', 'Model Address：',model_address]
        # if channel_num=='3':
        #     self.out.extend(['mean0,mean1,mean2:',mean0,',',mean1,',',mean2,' std0,std1,std2:',std0,',',std1,',',std2, '\n'])
        # elif channel_num=='1':
        #     self.out.extend(['mean0:',mean0,'   std0:',std0])
        self.clean_img_address, self.adv_img_address, self.dataset_name, self.model_address, self.resize, self.centercrop, self.mean0, self.mean1, self.mean2, self.std0, self.std1, self.std2=\
            clean_img_address.replace('\\', '/'), adv_img_address.replace('\\', '/'), dataset_name, model_address.replace('\\', '/'), int(600), int(600), float(0.485), float(0.456), float(0.406), float(0.229), float(0.224), float(0.225)
    def run(self):

        test_result = self.test()
        self.update_datasettest.emit(test_result)
    def test(self):
        if self.dataset_name == "uc":
            root = "Data\Scene\\UCMerced_LandUse\\val"
        elif self.dataset_name == "mstar":
            root = "Data\目标\MSTAR-10\\val"
        elif self.dataset_name == "fgsc23":
            root = "Data\目标\\FGSC-23\\val"
        elif self.dataset_name == "fusarship":
            root = "Data\目标\\FUSAR_Ship\\val"
        elif self.dataset_name == "sortedcars":
            root = "Data\目标\\Sorted_Cars\\val"
        sub_dir = os.listdir(root)
        since = time.time()
        # load images
        # img_clean = read_image(self.clean_img_address)
        # img_adv = read_image(self.adv_img_address)
        img_clean = Image.open(self.clean_img_address)
        img_adv = Image.open(self.adv_img_address)
        if self.dataset_name == "fusarship":
            img_adv = img_adv.convert('L')
            img_adv = img_adv.resize((512,512))
        elif self.dataset_name == "mstar":
            img_adv = img_adv.convert('L')
            img_adv = img_adv.resize((128,128))
        else:
            img_adv = img_adv.resize((224,224))

        trans_Tensor = transforms.ToTensor()
        img_clean = trans_Tensor(img_clean)
        img_adv = trans_Tensor(img_adv)
        print(img_adv.shape)


        # Image Pre-Transform
        if self.dataset_name == "uc":
            input_tensor_clean = normalize(resize(img_clean, (224, 224)) , [0.44979182, 0.48921227, 0.48212156],
                                     [0.19673954, 0.20322968, 0.21901236])
            input_tensor_adv = normalize(resize(img_adv, (224, 224)) , [0.44979182, 0.48921227, 0.48212156],
                                     [0.19673954, 0.20322968, 0.21901236])
        elif self.dataset_name == "fgsc23":
            input_tensor_clean = normalize(resize(img_clean, (224, 224)) , [0.352978, 0.373653, 0.359517],
                                     [0.4979, 0.4846, 0.4829])
            input_tensor_adv = normalize(resize(img_adv, (224, 224)) , [0.352978, 0.373653, 0.359517],
                                     [0.4979, 0.4846, 0.4829])

        elif self.dataset_name == "fusarship":
            input_tensor_clean = normalize(resize(img_clean,(512,512)), [0,  ],
                                           [1,  ])
            input_tensor_adv = normalize(resize(img_adv,(512,512)), [0,  ],
                                         [1,  ])

        elif self.dataset_name == "mstar":
            input_tensor_clean = normalize(resize(img_clean, (128, 128)) , [0.184, ],
                                     [0.119, ])
            input_tensor_adv = normalize(resize(img_adv, (128, 128)) , [0.184, ],
                                     [0.119, ])
        # Feed them to model
        print(self.model_address)
        model = torch.load(self.model_address)
        if self.dataset_name == 'fusarship' or self.dataset_name == 'mstar':
            cam_extractor = cam.CAM(model,input_shape=(1,224,224))
            use_gpu = torch.cuda.is_available()
            model.eval()

            input_tensor_clean = input_tensor_clean.cuda()
            input_tensor_adv = input_tensor_adv.cuda()

            out_1 = model(input_tensor_clean.unsqueeze(0))
            out_2 = model(input_tensor_adv.unsqueeze(0))

            _,indices_clean = torch.max(out_1,1)
            print(indices_clean)
            _,indices_adv = torch.max(out_2,1)
            result_clean = sub_dir[indices_clean]
            result_adv = sub_dir[indices_adv] # 具体预测类别

            percentage_clean = torch.nn.functional.softmax(out_1, dim=1)[0] * 100
            percentage_adv = torch.nn.functional.softmax(out_2, dim=1)[0] * 100  # softmax全部

            perc_clean = percentage_clean[int(indices_clean)].item()
            perc_adv = percentage_adv[int(indices_adv)].item()  # softmax最大

            time_elapsed = time.time() - since

            # ----------------------特征可视化------------------------------
            activation_clean_map = cam_extractor(out_1.squeeze(0).argmax().item(), out_1)
            activation_adv_map = cam_extractor(out_2.squeeze(0).argmax().item(), out_2)
            if self.dataset_name == "fusarship":
                activation_clean_map =  activation_clean_map
                activation_adv_map =  activation_adv_map
            elif self.dataset_name == "mstar":
                activation_clean_map = 1 - activation_clean_map
                activation_adv_map = 1 - activation_adv_map
            activation_clean_map = torch.unsqueeze(activation_clean_map,0)
            # Visualize the raw CAM
            img_clean_show = np.repeat(img_clean, 3, axis=0)

            feature_result_clean = overlay_mask(to_pil_image(img_clean_show),
                                                to_pil_image(activation_clean_map, mode='F').resize((64,64)), alpha=0.5)

            activation_adv_map = torch.unsqueeze(activation_adv_map, 0)
            # Visualize the raw CAM
            img_adv_show = np.repeat(img_adv, 3, axis=0)
            feature_result_adv = overlay_mask(to_pil_image(img_adv_show), to_pil_image(activation_adv_map, mode='F').resize((64,64)), alpha=0.5)
            # Display it

        elif self.dataset_name == "uc" or self.dataset_name == "fgsc23" or self.dataset_name == "sortedcars":
            cam_extractor = cam.CAM(model)
            use_gpu = torch.cuda.is_available()
            model.eval()

            input_tensor_clean = input_tensor_clean.cuda()
            input_tensor_adv = input_tensor_adv.cuda()

            out_1 = model(input_tensor_clean.unsqueeze(0))
            out_2 = model(input_tensor_adv.unsqueeze(0))

            _, indices_clean = torch.max(out_1, 1)
            print(indices_clean)
            _, indices_adv = torch.max(out_2, 1)
            result_clean = sub_dir[indices_clean]
            result_adv = sub_dir[indices_adv]  # 具体预测类别

            percentage_clean = torch.nn.functional.softmax(out_1, dim=1)[0] * 100
            percentage_adv = torch.nn.functional.softmax(out_2, dim=1)[0] * 100  # softmax全部

            perc_clean = percentage_clean[int(indices_clean)].item()
            perc_adv = percentage_adv[int(indices_adv)].item()  # softmax最大

            time_elapsed = time.time() - since

            # ---------------------------特征可视化------------------------------
            activation_clean_map = cam_extractor(out_1.squeeze(0).argmax().item(), out_1)
            activation_adv_map = cam_extractor(out_2.squeeze(0).argmax().item(), out_2)

            # Visualize the raw CAM
            feature_result_clean = overlay_mask(to_pil_image(img_clean),
                                                to_pil_image(activation_clean_map.squeeze(0), mode='F'), alpha=0.5)
            feature_result_adv = overlay_mask(to_pil_image(img_adv),
                                              to_pil_image(activation_adv_map.squeeze(0), mode='F'), alpha=0.5)
            # Display it

       # --------------------------------结果展示----------------------------------------
        self.out.extend(['\n','Test Time：',time_elapsed,'s','\n','Maximum Confidence Score for Benign Image： ',float(perc_clean),
                         '\n','Maximum Confidence Score for Adversarial Image： ',float(perc_adv),'\n','Predicted Class of Benign Image： ',result_clean,'\n',
                        "Predicted Class of Adversarial Image：", result_adv])
        out = [str(i) for i in self.out]
        out = "".join(out)
        test_out_log = out.split('\n')
        print(test_out_log)
        return ({0:out,1:sub_dir,2:percentage_clean,3: percentage_adv,4:feature_result_clean, 5:feature_result_adv})

if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    train = QtWidgets.QDialog()
    ui = Ui_CNN_data_test()
    ui.setupUi(train)
    ui.caolianjie()
    train.show()
    sys.exit(app.exec_())