# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'CNN_jiagu_singlesource.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


import os
import time
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
from tqdm import trange
import numpy as np
import pyttsx3
import matplotlib.pyplot as plt
import torch
from torchvision import datasets, models, transforms
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import QIcon
from openpyxl import load_workbook
from PyQt5.Qt import QThread, QImage
from PyQt5.Qt import pyqtSignal
from trades import trades_loss, at_loss
from tqdm import tqdm
from sklearn.metrics import confusion_matrix
from A_ConvNet import A_ConvNet, A_ConvNet_uc, A_ConvNet_fusarship
from art.estimators.classification import PyTorchClassifier
from art.attacks.evasion import ProjectedGradientDescent
from torch.utils.data import TensorDataset, DataLoader
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
import torch.nn.functional as F
from vit_model import VisionTransformer

class Ui_Form_jiagu_singlesource(object):
    def setupUi(self, Form_jiagu_singlesource):
        Form_jiagu_singlesource.setObjectName("Form_jiagu_singlesource")
        Form_jiagu_singlesource.resize(1293, 577)
        self.training_show = QtWidgets.QLabel(Form_jiagu_singlesource)
        self.training_show.setGeometry(QtCore.QRect(1, 390, 729, 189))
        self.training_show.setStyleSheet("background-color: rgb(127, 130, 136);\n"
                                         "")
        self.training_show.setFrameShadow(QtWidgets.QFrame.Raised)
        self.training_show.setLineWidth(3)
        self.training_show.setText("")
        self.training_show.setScaledContents(False)
        self.training_show.setAlignment(QtCore.Qt.AlignLeading | QtCore.Qt.AlignLeft | QtCore.Qt.AlignTop)
        self.training_show.setObjectName("training_show")
        self.label_image_show_models = QtWidgets.QLabel(Form_jiagu_singlesource)
        self.label_image_show_models.setGeometry(QtCore.QRect(740, 10, 541, 501))
        self.label_image_show_models.setStyleSheet("background-color: rgb(255, 255, 255);")
        self.label_image_show_models.setText("")
        self.label_image_show_models.setObjectName("label_image_show_models")
        self.label_56 = QtWidgets.QLabel(Form_jiagu_singlesource)
        self.label_56.setGeometry(QtCore.QRect(40, 140, 181, 41))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.label_56.setFont(font)
        self.label_56.setObjectName("label_56")
        self.pushButton_train = QtWidgets.QPushButton(Form_jiagu_singlesource)
        self.pushButton_train.setGeometry(QtCore.QRect(300, 360, 156, 23))
        self.pushButton_train.setObjectName("pushButton_train")
        self.label_57 = QtWidgets.QLabel(Form_jiagu_singlesource)
        self.label_57.setGeometry(QtCore.QRect(40, 20, 231, 41))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.label_57.setFont(font)
        self.label_57.setObjectName("label_57")
        self.label_58 = QtWidgets.QLabel(Form_jiagu_singlesource)
        self.label_58.setGeometry(QtCore.QRect(40, 240, 161, 41))
        font = QtGui.QFont()
        font.setFamily("Times New Roman")
        font.setPointSize(12)
        self.label_58.setFont(font)
        self.label_58.setObjectName("label_58")
        self.frame = QtWidgets.QFrame(Form_jiagu_singlesource)
        self.frame.setGeometry(QtCore.QRect(70, 60, 631, 80))
        self.frame.setFrameShape(QtWidgets.QFrame.StyledPanel)
        self.frame.setFrameShadow(QtWidgets.QFrame.Raised)
        self.frame.setObjectName("frame")
        self.radioButton_densenet121 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_densenet121.setGeometry(QtCore.QRect(360, 10, 115, 31))
        self.radioButton_densenet121.setAutoExclusive(True)
        self.radioButton_densenet121.setObjectName("radioButton_densenet121")
        self.radioButton_vgg19 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_vgg19.setGeometry(QtCore.QRect(190, 30, 86, 41))
        self.radioButton_vgg19.setAutoExclusive(True)
        self.radioButton_vgg19.setObjectName("radioButton_vgg19")
        self.radioButton_vit = QtWidgets.QRadioButton(self.frame)
        self.radioButton_vit.setGeometry(QtCore.QRect(530, 10, 115, 31))
        self.radioButton_vit.setAutoExclusive(True)
        self.radioButton_vit.setObjectName("radioButton_vit")
        self.radioButton_resnet50 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_resnet50.setGeometry(QtCore.QRect(20, 35, 151, 31))
        self.radioButton_resnet50.setAutoExclusive(True)
        self.radioButton_resnet50.setObjectName("radioButton_resnet50")
        self.radioButton_vgg16 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_vgg16.setGeometry(QtCore.QRect(190, 10, 115, 31))
        self.radioButton_vgg16.setAutoExclusive(True)
        self.radioButton_vgg16.setObjectName("radioButton_vgg16")
        self.radioButton_mobilenet = QtWidgets.QRadioButton(self.frame)
        self.radioButton_mobilenet.setGeometry(QtCore.QRect(530, 30, 115, 41))
        self.radioButton_mobilenet.setAutoExclusive(True)
        self.radioButton_mobilenet.setObjectName("radioButton_mobilenet")
        self.radioButton_resnet18 = QtWidgets.QRadioButton(self.frame)
        self.radioButton_resnet18.setGeometry(QtCore.QRect(20, 5, 115, 31))
        self.radioButton_resnet18.setChecked(True)
        self.radioButton_resnet18.setAutoExclusive(True)
        self.radioButton_resnet18.setObjectName("radioButton_resnet18")
        self.radioButton_squeezenet = QtWidgets.QRadioButton(self.frame)
        self.radioButton_squeezenet.setGeometry(QtCore.QRect(360, 30, 161, 41))
        self.radioButton_squeezenet.setAutoExclusive(True)
        self.radioButton_squeezenet.setObjectName("radioButton_squeezenet")
        self.frame_2 = QtWidgets.QFrame(Form_jiagu_singlesource)
        self.frame_2.setGeometry(QtCore.QRect(40, 180, 691, 51))
        self.frame_2.setFrameShape(QtWidgets.QFrame.StyledPanel)
        self.frame_2.setFrameShadow(QtWidgets.QFrame.Raised)
        self.frame_2.setObjectName("frame_2")
        self.radioButton_mstar = QtWidgets.QRadioButton(self.frame_2)
        self.radioButton_mstar.setGeometry(QtCore.QRect(140, 20, 101, 16))
        self.radioButton_mstar.setChecked(False)
        self.radioButton_mstar.setObjectName("radioButton_mstar")
        self.radioButton_fgsc23 = QtWidgets.QRadioButton(self.frame_2)
        self.radioButton_fgsc23.setGeometry(QtCore.QRect(270, 20, 111, 16))
        self.radioButton_fgsc23.setObjectName("radioButton_fgsc23")
        self.radioButton_fusarship = QtWidgets.QRadioButton(self.frame_2)
        self.radioButton_fusarship.setGeometry(QtCore.QRect(410, 20, 121, 16))
        self.radioButton_fusarship.setObjectName("radioButton_fusarship")
        self.radioButton_UC = QtWidgets.QRadioButton(self.frame_2)
        self.radioButton_UC.setGeometry(QtCore.QRect(50, 20, 89, 16))
        self.radioButton_UC.setChecked(True)
        self.radioButton_UC.setObjectName("radioButton_UC")
        self.radioButton_sortedcars = QtWidgets.QRadioButton(self.frame_2)
        self.radioButton_sortedcars.setGeometry(QtCore.QRect(560, 20, 121, 16))
        self.radioButton_sortedcars.setChecked(False)
        self.radioButton_sortedcars.setObjectName("radioButton_sortedcars")
        self.frame_3 = QtWidgets.QFrame(Form_jiagu_singlesource)
        self.frame_3.setGeometry(QtCore.QRect(40, 280, 641, 41))
        self.frame_3.setFrameShape(QtWidgets.QFrame.StyledPanel)
        self.frame_3.setFrameShadow(QtWidgets.QFrame.Raised)
        self.frame_3.setObjectName("frame_3")
        self.radioButton_TRADES = QtWidgets.QRadioButton(self.frame_3)
        self.radioButton_TRADES.setGeometry(QtCore.QRect(390, 10, 109, 16))
        self.radioButton_TRADES.setObjectName("radioButton_TRADES")
        self.radioButton_AT = QtWidgets.QRadioButton(self.frame_3)
        self.radioButton_AT.setGeometry(QtCore.QRect(220, 10, 101, 16))
        self.radioButton_AT.setChecked(False)
        self.radioButton_AT.setObjectName("radioButton_AT")
        self.radioButton_ensemble = QtWidgets.QRadioButton(self.frame_3)
        self.radioButton_ensemble.setGeometry(QtCore.QRect(50, 10, 101, 16))
        self.radioButton_ensemble.setChecked(True)
        self.radioButton_ensemble.setObjectName("radioButton_ensemble")
        self.checkBox = QtWidgets.QCheckBox(Form_jiagu_singlesource)
        self.checkBox.setGeometry(QtCore.QRect(90, 330, 231, 19))
        self.checkBox.setObjectName("checkBox")

        self.retranslateUi(Form_jiagu_singlesource)
        QtCore.QMetaObject.connectSlotsByName(Form_jiagu_singlesource)

    def retranslateUi(self, Form_jiagu_singlesource):
        _translate = QtCore.QCoreApplication.translate
        Form_jiagu_singlesource.setWindowTitle(_translate("Form_jiagu_singlesource", "Proactive Defense"))
        Form_jiagu_singlesource.setWindowIcon(QIcon("./1.ico"))
        self.label_56.setText(_translate("Form_jiagu_singlesource", "Select the Datasets："))
        self.pushButton_train.setText(_translate("Form_jiagu_singlesource", "Improve the Model"))
        self.label_57.setText(_translate("Form_jiagu_singlesource", "Model Selection:"))
        self.label_58.setText(_translate("Form_jiagu_singlesource", "Defense Methods："))
        self.radioButton_densenet121.setText(_translate("Form_jiagu_singlesource", "DenseNet121"))
        self.radioButton_vgg19.setText(_translate("Form_jiagu_singlesource", "VGG19"))
        self.radioButton_vit.setText(_translate("Form_jiagu_singlesource", "vit"))
        self.radioButton_resnet50.setText(_translate("Form_jiagu_singlesource", "ResNet50"))
        self.radioButton_vgg16.setText(_translate("Form_jiagu_singlesource", "VGG16"))
        self.radioButton_mobilenet.setText(_translate("Form_jiagu_singlesource", "A_ConvNet"))
        self.radioButton_resnet18.setText(_translate("Form_jiagu_singlesource", "ResNet18"))
        self.radioButton_squeezenet.setText(_translate("Form_jiagu_singlesource", "SqueezeNet"))
        self.radioButton_mstar.setText(_translate("Form_jiagu_singlesource", "  MSTAR"))
        self.radioButton_fgsc23.setText(_translate("Form_jiagu_singlesource", "  FGSC-23"))
        self.radioButton_fusarship.setText(_translate("Form_jiagu_singlesource", "  FUSAR-Ship"))
        self.radioButton_UC.setText(_translate("Form_jiagu_singlesource", "UC"))
        self.radioButton_sortedcars.setText(_translate("Form_jiagu_singlesource", "AID"))
        self.radioButton_TRADES.setText(_translate("Form_jiagu_singlesource", "Trades"))
        self.radioButton_AT.setText(_translate("Form_jiagu_singlesource", " PGD-AT"))
        self.radioButton_ensemble.setText(_translate("Form_jiagu_singlesource", "Ensemble"))
        self.checkBox.setText(_translate("Form_jiagu_singlesource", "If using pretrained model"))

    def caolianjie(self):
        self.pushButton_train.clicked.connect(self.clear_all)
        self.pushButton_train.clicked.connect(
            lambda: self.CNN_jiagu_singlesource(
                self.radioButton_resnet18.isChecked(),
                self.radioButton_resnet50.isChecked(),
                self.radioButton_vgg16.isChecked(),
                self.radioButton_vgg19.isChecked(),
                self.radioButton_densenet121.isChecked(),
                self.radioButton_squeezenet.isChecked(),
                self.radioButton_vit.isChecked(),
                self.radioButton_mstar.isChecked(),
                self.radioButton_UC.isChecked(),
                self.radioButton_fgsc23.isChecked(),
                self.radioButton_fusarship.isChecked(),
                self.radioButton_sortedcars.isChecked(),
                self.radioButton_AT.isChecked(),
                self.radioButton_TRADES.isChecked(),
                self.radioButton_ensemble.isChecked(),
                self.checkBox.isChecked()
            ))

    def clear_all(self):

        self.training_show.setText('Generate Robust Model')
        self.label_image_show_models.setPixmap(QtGui.QPixmap(""))
        self.label_image_show_models.repaint()

    def get_CNN_jiagu_singlesource_result(self, result):
        self.training_show.setText('Done!\nRecognition on Benign Data:{}\nAddress of New Robust Model：pths/{}_{}.pkl'.format(result[5]*100,result[2],result[4]))
        self.training_show.repaint()

        test_cm = result[0]

        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False

        plt.imshow(test_cm, interpolation='nearest', cmap=plt.cm.Oranges)
        # plt.title('混淆矩阵')
        plt.colorbar()
        sub_dir = result[1]
        indices = range(len(sub_dir))
        plt.xticks(indices, sub_dir)
        plt.xticks(rotation=270)
        plt.yticks(indices, sub_dir)
        plt.tick_params(labelsize=8)
        print(test_cm.shape)
        print(test_cm)
        print(len(sub_dir))
        iters = np.reshape([[[i, j] for j in range(len(sub_dir))] for i in range(len(sub_dir))], (test_cm.size, 2))
        if result[2] == 'mstar':
            type_size = 9
        elif result[2] == 'uc':
            type_size = 5
        for i, j in iters:
            plt.text(j, i, '%.0f' % (test_cm[i, j]), horizontalalignment='center',
                     verticalalignment='center', fontdict={'size': type_size, 'color': 'black'})
        plt.xlabel('Predicted Label')
        plt.ylabel('Groundtruth Label')
        plt.tight_layout()
        plt.savefig('result_image/{}_{}_{}.jpg'.format(result[2], result[3], result[4]))
        plt.close('all')
        self.openimage_label_image_show_models('result_image/{}_{}_{}.jpg'.format(result[2], result[3], result[4]))

    def CNN_jiagu_singlesource(self, resnet18_ifuse, resnet50_ifuse, vgg16_ifuse, vgg19_ifuse, densenet121_ifuse,
                               squeezenet_ifuse,
                               vit_ifuse, mstar_ifuse, uc_ifuse, fgsc23_ifuse, fusarship_ifuse,aid_ifuse,
                               at_ifuse, trades_ifuse,ensemble_ifuse, if_pretrained
                               ):

        self.thread_CNN_jiagu_singlesource = Thread_CNN_jiagu_singlesource(resnet18_ifuse, resnet50_ifuse, vgg16_ifuse,
                                                                           vgg19_ifuse, densenet121_ifuse,
                                                                           squeezenet_ifuse,
                                                                           vit_ifuse, mstar_ifuse,
                                                                           uc_ifuse, fgsc23_ifuse, fusarship_ifuse,aid_ifuse,
                                                                           at_ifuse, trades_ifuse,ensemble_ifuse, if_pretrained
                                                                           )
        self.thread_CNN_jiagu_singlesource.update_jiagu_singlesource.connect(self.get_CNN_jiagu_singlesource_result)
        self.thread_CNN_jiagu_singlesource.start()
        self.thread_CNN_jiagu_singlesource.exec()

    def openimage_label_image_show_models(self, imgName):
        imgName = imgName.replace('\\', '/')

        jpg = QtGui.QPixmap(imgName).scaled(self.label_image_show_models.width(), self.label_image_show_models.height())
        self.label_image_show_models.setPixmap(jpg)
        self.label_image_show_models.repaint()

class Ensemble(nn.Module):
    def __init__(self, models):
        super(Ensemble, self).__init__()
        self.models = models
        assert len(self.models) > 0

    def forward(self, x):
        if len(self.models) > 1:
            outputs = 0
            for model in self.models:
                outputs += F.softmax(model(x), dim=-1)
            output = outputs / len(self.models)
            output = torch.clamp(output, min=1e-40)
            return torch.log(output)
        else:
            return self.models[0](x)
class Thread_CNN_jiagu_singlesource(QThread):
    update_jiagu_singlesource = pyqtSignal(dict)

    def __init__(self,
                 resnet18_ifuse, resnet50_ifuse, vgg16_ifuse, vgg19_ifuse, densenet121_ifuse, squeezenet_ifuse,
                 vit_ifuse, mstar_ifuse, uc_ifuse, fgsc23_ifuse, fusarship_ifuse,aid_ifuse, at_ifuse,
                 trades_ifuse,ensemble_ifuse, if_pretrained
                 ):
        super().__init__()

        self.resnet18_ifuse, self.resnet50_ifuse, self.vgg16_ifuse, self.vgg19_ifuse, self.densenet121_ifuse, \
        self.squeezenet_ifuse, self.vit_ifuse, self.mstar_ifuse, \
        self.uc_ifuse, self.fgsc23_ifuse, self.fusarship_ifuse,self.aid_ifuse, self.at_ifuse, self.trades_ifuse, self.ensemble_ifuse,self.ifpretrained = \
            resnet18_ifuse, resnet50_ifuse, vgg16_ifuse, vgg19_ifuse, densenet121_ifuse, squeezenet_ifuse, \
            vit_ifuse, mstar_ifuse, uc_ifuse, fgsc23_ifuse, fusarship_ifuse,aid_ifuse, at_ifuse, trades_ifuse,ensemble_ifuse, if_pretrained

    def run(self):

        test_result = self.image_jiagu_all()
        self.update_jiagu_singlesource.emit(test_result)

    def image_jiagu_all(self):

        if self.resnet18_ifuse:
            model_name = 'resnet18'
        if self.resnet50_ifuse:
            model_name = 'resnet50'
        if self.vgg16_ifuse:
            model_name = 'vgg16'
        if self.vgg19_ifuse:
            model_name = 'vgg19'
        if self.densenet121_ifuse:
            model_name = 'densenet121'
        if self.squeezenet_ifuse:
            model_name = 'squeezenet'
        if self.vit_ifuse:
            model_name = 'vit'

        if self.mstar_ifuse:
            data_name = 'mstar'
            sub_dir = os.listdir(r'Data\Targets\MSTAR-10\train')
            mean = 0.184
            std = 0.119
            dataloders, dataset_sizes = self.load_mstar()
            data_npy = np.load('npy_save/mstar_train_normalized.npy')
            label_npy = np.load('npy_save/mstar_train_labels.npy')

        if self.uc_ifuse:
            data_name = 'uc'
            sub_dir = os.listdir(r'Data\Scene\UCMerced_LandUse\train')
            dataloders, dataset_sizes = self.load_uc()
            mean = 0.44979182
            std = 0.21901236
            data_npy = np.load('npy_save/uc_train_normalized.npy')
            label_npy = np.load('npy_save/uc_train_labels.npy')
        if self.fusarship_ifuse:
            data_name = 'fusarship'
            sub_dir = os.listdir(r'Data\Targets\FUSAR_Ship\train')
            dataloders, dataset_sizes = self.load_fusarship()
            data_npy = np.load('npy_save/fusarship_train_normalized.npy')
            label_npy = np.load('npy_save/fusarship_train_labels.npy')
        if self.aid_ifuse:
            data_name = 'AID'
            sub_dir = os.listdir('Data/Scene/AID/train')
            dataloders, dataset_sizes = self.load_aid()
            data_npy = np.load('npy_save/aid_train_normalized.npy')
            label_npy = np.load('npy_save/aid_train_labels.npy')


        # attack = ProjectedGradientDescent(estimator=classifier, batch_size=8, eps=3 / 100, eps_step=0.01, max_iter=5)
        criterion = nn.CrossEntropyLoss()
        if self.ifpretrained:
            # print('dddddddd')
            if os.path.exists('pkl_save/{}_{}_pre.pkl'.format(data_name, model_name)):
                model_ori = torch.load('pkl_save/{}_{}_pre.pkl'.format(data_name, model_name))
            else:
                model_ori = torch.load('pkl_save/{}_{}.pkl'.format(data_name, model_name))
        else:
            model_ori = self.model_load(model=model_name, dataset=data_name, ifpretrained=False)
        if self.mstar_ifuse:
            optimizer = optim.Adam(model_ori.parameters(), lr=0.001, eps=1e-08)
            classifier = PyTorchClassifier(
                model=model_ori,
                loss=criterion,
                clip_values=(-0.184 / 0.119, (1 - 0.184) / 0.119),
                optimizer=optimizer,
                input_shape=(1, 128, 128),
                nb_classes=10
            )
        elif self.uc_ifuse:
            optimizer = optim.SGD(model_ori.parameters(), lr=0.001, momentum=0.9)
            classifier = PyTorchClassifier(
                model=model_ori,
                loss=criterion,
                clip_values=(-0.48921227 / 0.20322968, (1 - 0.44979182) / 0.196739541),
                optimizer=optimizer,
                input_shape=(3, 224, 224),
                nb_classes=21,
            )
        elif self.fusarship_ifuse:
            optimizer = optim.SGD(model_ori.parameters(), lr=0.001, momentum=0.9)
            classifier = PyTorchClassifier(
                model=model_ori,
                loss=criterion,
                clip_values=(0, 1),
                optimizer=optimizer,
                input_shape=(1, 224, 224),
                nb_classes=4,
            )
        elif self.aid_ifuse:
            optimizer = optim.SGD(model_ori.parameters(), lr=0.001, momentum=0.9)
            classifier = PyTorchClassifier(
                model=model_ori,
                loss=criterion,
                clip_values=(-0.4093274/0.1944, (1-0.3685047)/0.1919),
                optimizer = optimizer,
                input_shape = (3, 224, 224),
                nb_classes = 30
            )



        if self.at_ifuse:
            jiagu_method_name = 'PGD-AT'
            print(jiagu_method_name)
            attack = ProjectedGradientDescent(estimator=classifier,batch_size=1,eps=0.125, eps_step=0.02,max_iter=50)
            x_train_adv_npy = attack.generate(x=data_npy)
            model_yijiagu = self.train_model_at(model_ori, x_train_adv_npy, label_npy, num_epochs=20)
            torch.save(model_yijiagu, 'pths/{}_{}_{}.pkl'.format(data_name, model_name, jiagu_method_name))
        if self.trades_ifuse:
            jiagu_method_name = 'Trades'
            print(jiagu_method_name)
            attack = ProjectedGradientDescent(estimator=classifier,batch_size=2,eps=0.125, eps_step=0.02,max_iter=50)
            x_train_adv_npy = attack.generate(x=data_npy)
            x_train_clean_and_adv_npy = np.vstack((x_train_adv_npy, x_train_adv_npy))
            label_clean_and_adv_npy = np.hstack((label_npy, label_npy))
            model_yijiagu = self.train_model_trades(model_ori, x_train_clean_and_adv_npy, label_clean_and_adv_npy,
                                                    num_epochs=20)
            torch.save(model_yijiagu, 'pths/{}_{}_{}.pkl'.format(data_name, model_name, jiagu_method_name))
        if self.ensemble_ifuse:
            jiagu_method_name = 'Ensemble'
            print(jiagu_method_name)
            model_yijiagu = self.train_model_ensemble(data_name)
            torch.save(model_yijiagu, 'pths/{}_{}.pkl'.format(data_name, jiagu_method_name))
        test_cleandata_cm, correct = self.test(model_yijiagu, dataloders['val'], dataset_sizes['val'])
        return ({0: test_cleandata_cm, 1: sub_dir, 2: data_name, 3: model_name, 4: jiagu_method_name, 5: correct})

    def test(self, model, dataloders, dataset_sizes):
        model.eval()
        running_corrects = 0.0

        # Iterate over data.
        preds_all = np.zeros(dataset_sizes)
        labels_all = np.zeros(dataset_sizes)
        i = 0
        for data in tqdm(dataloders):
            # get the inputs
            inputs, labels = data
            # wrap them in Variable
            inputs = Variable(inputs.to(device))
            labels = Variable(labels.to(device))
            # zero the parameter gradients
            outputs = model(inputs)
            _, preds = torch.max(outputs.data, 1)
            running_corrects += torch.sum(preds == labels.data).to(torch.float32)
            preds_all[i * preds.shape[0]:(i + 1) * preds.shape[0]] = preds.cpu().detach().numpy()
            labels_all[i * preds.shape[0]: (i + 1) * preds.shape[0]] = labels.cpu().detach().numpy()
            i += 1
        correct = running_corrects / dataset_sizes
        test_cm = confusion_matrix(labels_all, preds_all)
        return test_cm, correct

    def train_model_at(self, model, x_train_adv_npy, label_npy, num_epochs=10):
        since = time.time()
        criterion = nn.CrossEntropyLoss()
        a = torch.from_numpy(x_train_adv_npy)
        b = torch.from_numpy(label_npy)
        train_adv_ids = TensorDataset(a, b)
        train_adv_loader = DataLoader(dataset=train_adv_ids, batch_size=1, shuffle=True)
        optimizer_ft = optim.Adam(model.parameters(), lr=0.001)
        scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=19, gamma=0.9)
        model.to(device)
        for epoch in trange(num_epochs):
            print('Epoch {}/{}'.format(epoch + 1, num_epochs))
            print('-' * 10)
            running_corrects = 0.0
            for data in train_adv_loader:
                x_data, label = data
                inputs = Variable(x_data.cuda())
                labels = Variable(label.cuda())
                # zero the parameter gradients
                optimizer_ft.zero_grad()
                # forward
                outputs = model(inputs)
                # print (outputs.shape)
                _, preds = torch.max(outputs.data, 1)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer_ft.step()
                running_corrects += torch.sum(preds == labels.data).to(torch.float32)
        time_elapsed = time.time() - since
        print('Training complete in {:.0f}m {:.0f}s'.format(
            time_elapsed // 60, time_elapsed % 60))
        # print('Best val Acc: {:4f}'.format(best_acc))
        # load best model weights
        return model

    def train_model_trades(self, model, x_train_clean_and_adv_npy, label_clean_and_adv_npy, num_epochs=10):
        since = time.time()
        criterion = nn.CrossEntropyLoss()
        a = torch.from_numpy(x_train_clean_and_adv_npy)
        b = torch.from_numpy(label_clean_and_adv_npy)
        train_adv_ids = TensorDataset(a, b)
        train_adv_loader = DataLoader(dataset=train_adv_ids, batch_size=1, shuffle=True)
        optimizer_ft = optim.Adam(model.parameters(), lr=0.001)
        scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=19, gamma=0.9)
        model.to(device)
        for epoch in trange(num_epochs):
            print('Epoch {}/{}'.format(epoch + 1, num_epochs))
            print('-' * 10)
            running_corrects = 0.0
            for data in train_adv_loader:
                x_data, label = data
                inputs = Variable(x_data.cuda())
                labels = Variable(label.cuda())
                # zero the parameter gradients
                optimizer_ft.zero_grad()
                # forward
                outputs = model(inputs)
                # print (outputs.shape)
                _, preds = torch.max(outputs.data, 1)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer_ft.step()
                running_corrects += torch.sum(preds == labels.data).to(torch.float32)
        time_elapsed = time.time() - since
        print('Training complete in {:.0f}m {:.0f}s'.format(
            time_elapsed // 60, time_elapsed % 60))
        # print('Best val Acc: {:4f}'.format(best_acc))
        # load best model weights
        return model

    def train_model_ensemble(self, datasetname):
        models = []
        model1 = nn.DataParallel(torch.load('pkl_save/{}_resnet50.pkl'.format(datasetname)))
        if os.path.exists('pkl_save/{}_vit.pkl'.format(datasetname)):
            model2 = nn.DataParallel(torch.load('pkl_save/{}_vit.pkl'.format(datasetname)))
        else:
            model2 = nn.DataParallel(torch.load('pkl_save/{}_A_ConvNet.pkl'.format(datasetname)))
        print(model1)
        print(model2)
        models.append(model1)
        models.append(model2)
        ensemble = Ensemble(models)
        return ensemble

    def model_load(self, model='vgg16', dataset='mstar', ifpretrained=True):
        if model == 'vgg16':
            if dataset == 'mstar':
                model_ft = models.vgg16(pretrained=ifpretrained)
                model_ft.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                model_ft.classifier[6] = nn.Linear(in_features=4096, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = models.vgg19(pretrained=True)
                model_ft.classifier[6] = nn.Linear(in_features=4096, out_features=21, bias=True)

        if model == 'vgg19':
            if dataset == 'mstar':
                model_ft = models.vgg19(pretrained=ifpretrained)
                model_ft.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                model_ft.classifier[6] = nn.Linear(in_features=4096, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = models.vgg16(pretrained=True)
                model_ft.classifier[6] = nn.Linear(in_features=4096, out_features=21, bias=True)


        elif model == 'resnet18':
            if dataset == 'mstar':
                model_ft = models.resnet18(pretrained=ifpretrained)
                model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
                num_ftrs = model_ft.fc.in_features
                model_ft.fc = nn.Linear(num_ftrs, 10)
            elif dataset == 'uc':
                model_ft = models.resnet18(pretrained=True)
                num_ftrs = model_ft.fc.in_features
                model_ft.fc = nn.Linear(num_ftrs, 21)


        elif model == 'resnet50':
            if dataset == 'mstar':
                model_ft = models.resnet50(pretrained=ifpretrained)
                model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                num_ftrs = model_ft.fc.in_features
                model_ft.fc = nn.Linear(num_ftrs, 10)
            elif dataset == 'uc':
                model_ft = models.resnet50(pretrained=ifpretrained)
                num_ftrs = model_ft.fc.in_features
                model_ft.fc = nn.Linear(num_ftrs, 21)


        elif model == 'squeezenet':
            if dataset == 'mstar':
                model_ft = models.squeezenet1_0(pretrained=ifpretrained)
                model_ft.features[0] = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2))
                model_ft.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))
            elif dataset == 'uc':
                model_ft = models.squeezenet1_0(pretrained=ifpretrained)
                model_ft.classifier[1] = nn.Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))

        elif model == 'vit':
            if dataset == 'mstar':
                model_ft = models.alexnet(pretrained=ifpretrained)
                model_ft.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                model_ft.classifier[6] = nn.Linear(in_features=4096, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = VisionTransformer(num_classes=21)

        elif model == 'densenet201':
            if dataset == 'mstar':
                model_ft = models.densenet201(pretrained=ifpretrained)
                model_ft.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3),
                                                    bias=False)
                model_ft.classifier = nn.Linear(in_features=1920, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = models.densenet201(pretrained=ifpretrained)
                model_ft.classifier = nn.Linear(in_features=1920, out_features=21, bias=True)

        elif model == 'inceptionv3':
            if dataset == 'mstar':
                model_ft = models.inception_v3(pretrained=True, transform_input=False)
                model_ft.Conv2d_1a_3x3.conv = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
                model_ft.AuxLogits.fc = nn.Linear(768, 10)
                model_ft.aux_logits = False
                model_ft.fc = nn.Linear(in_features=2048, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = models.inception_v3(pretrained=ifpretrained)
                model_ft.AuxLogits.fc = nn.Linear(2048, 21)
                model_ft.aux_logits = False
                model_ft.fc = nn.Linear(in_features=2048, out_features=21, bias=True)
            else:
                print('目前只支持uc数据集')

        elif model == 'mnasnet1_0':
            if dataset == 'mstar':
                model_ft = models.mnasnet1_0(pretrained=ifpretrained)
                model_ft.layers[0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                model_ft.classifier[1] = nn.Linear(in_features=1280, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = models.mnasnet1_0(pretrained=ifpretrained)
                model_ft.classifier[1] = nn.Linear(in_features=1280, out_features=21, bias=True)

        elif model == 'shufflenet_v2':
            if dataset == 'mstar':
                model_ft = models.shufflenet_v2_x1_0(pretrained=ifpretrained)
                model_ft.conv1[0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)

                model_ft.fc = nn.Linear(in_features=1024, out_features=10, bias=True)
            elif dataset == 'uc':
                model_ft = models.shufflenet_v2_x1_0(pretrained=ifpretrained)
                model_ft.fc = nn.Linear(in_features=1024, out_features=21, bias=True)

        else:
            print('输入有误，请做好检查')

        return model_ft

    def load_mstar(self, model='vgg16', batch_size=16):
        data_transforms = {
            'train': transforms.Compose([
                transforms.Grayscale(1),
                transforms.Resize(128),
                transforms.CenterCrop(128),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize((0.184,), (0.119,))

            ]),
            'val': transforms.Compose([
                transforms.Grayscale(1),
                transforms.Resize(128),
                transforms.CenterCrop(128),
                transforms.ToTensor(),
                transforms.Normalize((0.184,), (0.119,))

            ])
        }
        data_dir = r'Data\Targets\MSTAR-10'
        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                                  data_transforms[x]) for x in ['train', 'val']}
        # wrap your data and label into Tensor
        train_len = len(image_datasets['train'])
        if_shuffle = {'train': True, 'val': False}
        dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],
                                                     batch_size=32,
                                                     shuffle=if_shuffle[x],
                                                     num_workers=0) for x in ['train', 'val']}

        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
        return dataloders, dataset_sizes

    def load_uc(self, model='vgg16', batch_size=16):

        data_transforms = {
            "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                         transforms.RandomHorizontalFlip(),
                                         transforms.ToTensor(),
                                         transforms.Normalize((0.44979182, 0.48921227, 0.48212156),
                                                              (0.19673954, 0.20322968, 0.21901236))]),
            "val": transforms.Compose([transforms.Resize((224, 224)),
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.44979182, 0.48921227, 0.48212156),
                                                            (0.19673954, 0.20322968, 0.21901236))])}

        data_dir = r'Data\Scene\UCMerced_LandUse'

        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                                  data_transforms[x]) for x in ['train', 'val']}
        # wrap your data and label into Tensor
        if_shuffle = {'train': True, 'val': False}
        dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],
                                                     batch_size=16,
                                                     shuffle=if_shuffle[x],
                                                     num_workers=0) for x in ['train', 'val']}

        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
        return dataloders, dataset_sizes

    def load_fusarship(model='vgg16'):
        data_transforms = {
            'train': transforms.Compose([
                transforms.Grayscale(1),
                transforms.Resize((224,224)),
                transforms.CenterCrop(224),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                # transforms.Normalize([0.033996, ], [0.05921, ])
            ]),
            'val': transforms.Compose([
                transforms.Grayscale(1),
                transforms.Resize((224, 224)),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                # transforms.Normalize([0.033996, ], [0.05921, ])
            ])
        }

        data_dir = r'Data\Targets\FUSAR_Ship'
        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                                  data_transforms[x]) for x in ['train', 'val']}
        # wrap your data and label into Tensor
        if_shuffle = {'train': True, 'val': False}
        dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],
                                                     batch_size=1,
                                                     shuffle=if_shuffle[x],
                                                     num_workers=0) for x in ['train', 'val']}

        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
        return dataloders, dataset_sizes

    def load_aid(self, model='vgg16', batch_size=16):

        data_transforms = {
            "train": transforms.Compose([transforms.Resize((224, 224)),
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.3977968, 0.4093274, 0.3685047), (0.2169, 0.1944,  0.1919))]),
            "val": transforms.Compose([transforms.Resize((224, 224)),
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.3977968, 0.4093274, 0.3685047), (0.2169, 0.1944,  0.1919))])}

        data_dir = r'Data\Scene\AID'

        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                                  data_transforms[x]) for x in ['train', 'val']}
        # wrap your data and label into Tensor
        if_shuffle = {'train': True, 'val': False}
        dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],
                                                     batch_size=16,
                                                     shuffle=if_shuffle[x],
                                                     num_workers=0) for x in ['train', 'val']}

        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
        return dataloders, dataset_sizes


    # def image_jiagu_all(self):
    #
    #     if self.resnet18_ifuse:
    #         model_name='resnet18'
    #     if self.resnet50_ifuse:
    #         model_name='resnet50'
    #     if self.vgg16_ifuse:
    #         model_name='vgg16'
    #     if self.vgg19_ifuse:
    #         model_name='vgg19'
    #     if self.densenet121_ifuse:
    #         model_name='densenet121'
    #     if self.squeezenet_ifuse:
    #         model_name='squeezenet'
    #     if self.alexnet_ifuse:
    #         model_name='alexnet'
    #     if self.A_ConvNet_ifuse:
    #         model_name='A_ConvNet'
    #
    #     if self.mstar_ifuse:
    #         data_name = 'mstar'
    #         sub_dir = os.listdir('Data\\MSTAR-10\\train')
    #         mean = 0.184
    #         std = 0.119
    #         dataloders, dataset_sizes = self.load_mstar()
    #         data_npy = np.load('npy_save/mstar_train_normalized.npy')
    #         label_npy = np.load('npy_save/mstar_train_labels.npy')
    #
    #     if self.uc_ifuse:
    #         data_name = 'uc'
    #         sub_dir = os.listdir('Data\\UCMerced_LandUse\\train')
    #         dataloders, dataset_sizes = self.load_uc()
    #         mean = 0.44979182
    #         std = 0.21901236
    #         data_npy = np.load('npy_save/uc_train_normalized.npy')
    #         label_npy = np.load('npy_save/uc_train_labels.npy')
    #     if self.fusarship_ifuse:
    #         data_name = 'fusarship'
    #         sub_dir = os.listdir('Data\\FUSAR_Ship\\train')
    #         dataloders, dataset_sizes = self.load_fusarship()
    #         data_npy = np.load('npy_save/fusarship_train_normalized.npy')
    #         label_npy = np.load('npy_save/fusarship_train_labels.npy')
    #
    #     # attack = ProjectedGradientDescent(estimator=classifier, batch_size=8, eps=3 / 100, eps_step=0.01, max_iter=5)
    #
    #
    #     if self.ifpretrained:
    #         # print('dddddddd')
    #         model_ori = torch.load('pkl_save/{}_{}.pkl'.format(data_name,model_name))
    #     else:
    #         model_ori = self.model_load(model=model_name, dataset=data_name,ifpretrained=False)
    #     if self.at_ifuse:
    #         jiagu_method_name = 'at'
    #         model_yijiagu = self.train_model_at(model_ori,dataloders,mean,std,data_npy,label_npy,num_epochs=10)
    #     if self.trades_ifuse:
    #         jiagu_method_name = 'trades'
    #         model_yijiagu = self.train_model_trades(model_ori,dataloders,mean,std,num_epochs=10)
    #     torch.save(model_yijiagu,'pths/{}_{}_{}.pth'.format(data_name,model_name,jiagu_method_name))
    #     test_cleandata_cm,correct = self.test(model_yijiagu,dataloders['val'],dataset_sizes['val'])
    #     return({0:test_cleandata_cm,1:sub_dir,2:data_name,3:model_name,4:jiagu_method_name,5:correct})
    # def test(self,model,dataloders,dataset_sizes):
    #     model.eval()
    #     running_corrects = 0.0
    #
    #     # Iterate over data.
    #     preds_all = np.zeros(dataset_sizes)
    #     labels_all = np.zeros(dataset_sizes)
    #     i = 0
    #     for data in tqdm(dataloders):
    #         # get the inputs
    #         inputs, labels = data
    #         # wrap them in Variable
    #         inputs = Variable(inputs.to(device))
    #         labels = Variable(labels.to(device))
    #         # zero the parameter gradients
    #         outputs = model(inputs)
    #         _, preds = torch.max(outputs.data, 1)
    #         running_corrects += torch.sum(preds == labels.data).to(torch.float32)
    #         preds_all[i*preds.shape[0]:(i+1)*preds.shape[0]] = preds.cpu().detach().numpy()
    #         labels_all[i * preds.shape[0]: (i + 1) * preds.shape[0]] = labels.cpu().detach().numpy()
    #         i+=1
    #     correct = running_corrects/dataset_sizes
    #     test_cm = confusion_matrix(labels_all, preds_all)
    #     return test_cm,correct
    # def train_model_at(self,model, dataloder, mean,std,data_npy,label_npy, num_epochs=10):
    #     since = time.time()
    #     best_model_wts = model.state_dict()
    #     best_acc = 0.0
    #     optimizer = optim.Adam(model.parameters(), lr=0.001)
    #     scheduler = lr_scheduler.StepLR(optimizer, step_size=19, gamma=0.9)
    #     model.to(device)
    #     for epoch in trange(num_epochs):
    #         print('Epoch {}/{}'.format(epoch + 1, num_epochs))
    #         print('-' * 10)
    #         # Each epoch has a training and validation phase
    #         for phase in ['train', 'val']:
    #             if phase == 'train':
    #                 scheduler.step()
    #                 model.train(True)  # Set model to training mode
    #             else:
    #                 model.train(False)  # Set model to evaluate mode
    #                 model.eval()
    #             # Iterate over data.
    #             for data in dataloder[phase]:
    #                 # get the inputs
    #                 inputs, labels = data
    #                 inputs = Variable(inputs.to(device))
    #                 labels = Variable(labels.to(device)
    #                                   )
    #                 # zero the parameter gradients
    #                 optimizer.zero_grad()
    #                 loss = at_loss(model=model,
    #                                x_natural=inputs,
    #                                y=labels,
    #                                optimizer=optimizer,
    #                                mean=mean,
    #                                std=std,
    #                                step_size=1 / 255,
    #                                epsilon=8 / 255,
    #                                perturb_steps=12,
    #                                )
    #                 # backward + optimize only if in training phase
    #                 if phase == 'train':
    #                     loss.backward()
    #                     optimizer.step()
    #     time_elapsed = time.time() - since
    #     print('Training complete in {:.0f}m {:.0f}s'.format(
    #         time_elapsed // 60, time_elapsed % 60))
    #     # print('Best val Acc: {:4f}'.format(best_acc))
    #     # load best model weights
    #     model.load_state_dict(best_model_wts)
    #     return model
    #
    # def train_model_trades(self,model, dataloder, mean,std, num_epochs=10):
    #     model.to(device)
    #     since = time.time()
    #     best_model_wts = model.state_dict()
    #     # best_acc = 0.0
    #     optimizer = optim.Adam(model.parameters(), lr=0.001)
    #     scheduler = lr_scheduler.StepLR(optimizer, step_size=19, gamma=0.9)
    #     for epoch in trange(num_epochs):
    #         print('Epoch {}/{}'.format(epoch + 1, num_epochs))
    #         print('-' * 10)
    #         # Each epoch has a training and validation phase
    #         for phase in ['train', 'val']:
    #             if phase == 'train':
    #                 scheduler.step()
    #                 model.train(True)  # Set model to training mode
    #             else:
    #                 model.train(False)  # Set model to evaluate mode
    #                 model.eval()
    #             # Iterate over data.
    #             for data in dataloder[phase]:
    #                 # get the inputs
    #                 inputs, labels = data
    #                 inputs = Variable(inputs.to(device))
    #                 labels = Variable(labels.to(device)
    #                                   )
    #                 # zero the parameter gradients
    #                 optimizer.zero_grad()
    #                 loss = trades_loss(model=model,
    #                                x_natural=inputs,
    #                                y=labels,
    #                                optimizer=optimizer,
    #                                mean=mean,
    #                                std=std,
    #                                step_size=1 / 255,
    #                                epsilon=4 / 255,
    #                                perturb_steps=8,
    #                                )
    #                 # backward + optimize only if in training phase
    #                 if phase == 'train':
    #                     loss.backward()
    #                     optimizer.step()
    #     time_elapsed = time.time() - since
    #     print('Training complete in {:.0f}m {:.0f}s'.format(
    #         time_elapsed // 60, time_elapsed % 60))
    #     # print('Best val Acc: {:4f}'.format(best_acc))
    #     # load best model weights
    #     model.load_state_dict(best_model_wts)
    #     return model


if __name__ == "__main__":
    import sys

    app = QtWidgets.QApplication(sys.argv)
    train = QtWidgets.QDialog()
    ui = Ui_Form_jiagu_singlesource()
    ui.setupUi(train)
    ui.caolianjie()
    train.show()
    sys.exit(app.exec_())